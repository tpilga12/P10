\section{Model predictive control}\label{se:model_predictive_control}
In this section, the design of the controller is elaborated. First the control problem is summarized thereafter Model predictive controller (MPC) is elaborated followed by the design of the MPC controller and ending with the implementation and results of the simulation. 

The simulation covered in chapter \ref{ch:simulation} is to be controlled with respect to the problems elaborated in section \ref{sec:problem_statement} and stated below. 
\begin{enumerate}
\item Flow variations due to large industries and natural phenomenons
\item Concentration variations due to large industries and natural phenomenons
\begin{enumerate}
	\item Chloride variations
	\item Phosphorus variations
	\item Nitrogen variations
	\item Organic matter variations
\end{enumerate}
\end{enumerate}


From the problem statement, it is given that flow and concentration variations must be kept to a minimum without causing overflow in the sewer. To achieve this, tanks are used. These are placed in the sewer network in locations where they are able to minimize flow and concentration variations into the WWTP. However, the output of these tanks must be controlled in a way such that overflow in the tank does not occur. Furthermore the size and location of these tanks can be hard to determine. Therefore implementing an optimal control, which can operate the system close to limits of the system, can help determine if the tank is located and dimensioned properly.
%Therefore the controller must control the output of these tanks in an optimal manner to keep the input variations to the WWTP at a minimum and still be controlled according to some constraints.

%To obtain such an optimal behavior MPC is chosen as stated in section \ref{sec:problem_statement}. MPC solves an optimization problem at each time instant, k, where the main point is to compute a control vector, u that is feed to the system. 

%is an advanced control method which depends on a dynamic model of the system. Where the model, constraints and a cost function is used to generate the most optimal sequence of control inputs to the system, thus obtaining a desired process behavior. However, only the first control input is used in the current timeslot. Hereafter, in the next timeslot, the MPC algorithm is recalculated to find the must optimal input signal for this timeslot and so on. In addition, MPC also take future disturbance into account thereby predicting an output sequence that is optimal including the disturbance. 
MPC algorithm consists of:
\\ 
\textbf{Cost function} or control objective, $\CMcal{J}$, is a criterion when measuring e.g. the difference between future outputs and a reference while at the same time having in mind that any control action is costly for the system. Therefore the price is measured in the cost function over the prediction horizon, $H_p$. This function is therefore minimized with respect to the future control input to minimize the cost \cite{mpc_control_lecture_notes}. %Furthermore, only the first control input from the vector is used in each time instant thus this optimization is process is calculated at each time step where a new control input is calculated \cite{mpc_control_lecture_notes}.

\textbf{Constraints} is an unique advantage of MPC. They can be applied to the process variables e.g. on the states of the system to keep them within a defined limit. %not allowing them to go below a certain value or above. 
Furthermore, they are usually written as inequality constraints, $Ax\leq b$, where the optimization problem is subject to the constraint \cite{mpc_control_lecture_notes}.   

\textbf{Prediction model} is as the name indicates, able to predict future system behavior. The model describes the in- and output behavior of the system over the prediction horizon \cite{mpc_control_lecture_notes}.  

% In figure \ref{fig:mpc_diagram} an illustration of a MPC controller is shown.
% \begin{figure}[H]
% 	\centering
% 	\includegraphics[width=0.60\textwidth]{report/control/pictures/mpc_diagram}
% 	\caption{Diagram of an MPC controller}
% 	\label{fig:mpc_diagram}
% \end{figure}



%The main advantage of MPC  Furthermore, MPC can be used with constraints to calculate the most optimal control output at the given timeslot and taking disturbance into the account. 
% In figure \ref{fig:control_of_sewer} it is shown that the MPC controller is setting the input to the pump.

% \begin{figure}[H]
% \centering
% \includegraphics[width=0.8\textwidth]{report/control/pictures/control_of_sewer.jpg}
% \caption{Block diagram of the system.}
% \label{fig:control_of_sewer}
% \end{figure}\fxnote{Der skal staa pumpe i stedet for tank}

% Where the iteration the in the MPC block can be described with the following items. 
% \begin{enumerate}
%        	\item Measurement is taken on the output if possible or it is taken directly from the states. If a state measurement is not available the state is estimated.
%        	\item Calculates a optimal set of predicted values over the prediction horizon according to a cost function and the constraints.
%        	\item The first element of the calculated control sequence is used as the control input.
%        	\item Repeat from 1.
% \end{enumerate}       

For MPC to optimize the system a cost function must be written to penalize variations of the flow output $Q(k+i|k)$ and the concentration output $C(k+i|k)$. Where k defines the prediction time and i is a value going from 1 to $H_p$. The cost functions for flow and concentration are:

\begin{equation}
\begin{aligned}
	 \CMcal{J} &= \sum_{i=1}^{H_p-1} || Q(k+i|k)C_1(k+i|k)-Q(k+i-1|k)C_1(k+i-1|k)||_{\CMcal{Q}_1(i)}^2 \\&+\sum_{i=1}^{H_p-1} || Q(k+i|k)C_2(k+i|k)-Q(k+i-1|k)C_2(k+i-1|k)||_{\CMcal{Q}_2(i)}^2 \\&+\sum_{i=1}^{H_p-1} || Q(k+i|k)C_3(k+i|k)-Q(k+i-1|k)C_3(k+i-1|k)||_{\CMcal{Q}_3(i)}^2\\&+\sum_{i=1}^{H_p-1} || Q(k+i|k)C_4(k+i|k)-Q(k+i-1|k)C_4(k+i-1|k)||_{\CMcal{Q}_4(i)}^2 \\& +\sum_{i=1}^{H_p-1} || Q(k+i|k)-Q(k+i-1|k)||_{\CMcal{Q}_5(i)}^2
\end{aligned}	
\end{equation}

Where $\CMcal{J}$ is the cost function that needs to be minimized, Q is the flow, C is the concentration and $\CMcal{Q}$ is a weighting parameter. The concentrations $C_1, C_2, C_3$ and $C_4$ are respectively chloride, phosphorus, nitrogen and organic matter levels in the wastewater. 
However, due to delimitations in section \ref{se:system_description} the concentrate is limited to a single component.
Due to time constraints, it has been decided to keep a focus on minimizing flow variations and limit the complexity of implementing MPC. 
%This has been done to limit the control problem and ease the computation, to begin with. 
The cost function is therefore limited to the following: 

\begin{equation}\label{eq:cost_function_height}
\begin{aligned}
	 \CMcal{J} = \sum_{i=1}^{H_p-1} || \hat{y}&(k+i|k)-\hat{y}(k+i-1|k)||_{\CMcal{Q}(i)}^2 \\[12pt]
% \end{equation}
% \begin{equation}\label{eq:state_eq_subject_to}
% 	\begin{aligned}
	\text{s.t.} \hspace{5mm}  \hat{x}(k+i+1) &= A\hat{x}(k+i|k)+B\hat{u}(k+i|k)+B_d\hat{d}(k+i|k) \\
						      \hat{y}(k+i)&= C\hat{x}(k+i|k) \\
						     x_{min} &\leq  x \leq x_{max} \\
						     u_{min} & \leq u \leq u_{max}
	\end{aligned}
\end{equation}
Where Q has been replaced with the output y as it can be measured directly from the state space system. The hat denotes a small signal value of y. This notation is used throughout the chapter. Where y corresponds to the height of fluid in the pipe. Minimizing height difference corresponds to minimizing flow differences, as to both describe the variation in the output of the sewer. Furthermore, the cost function is subject to constraints on the states and the control input. Both the states and the control input have a lower and upper constraint corresponding respectively to the bottom of the pipe and the top of the pipe and respectively to the minimum and maximum control input to the pump. In order for the controller to minimize the variations in the output, it must be able to predict future events from the current state. Therefore, by iterating the linear model, obtained in section \ref{se:linearization}, for the duration of the prediction horizon the controller is able to predict future states \cite{maciejowski2002predictive}.

%Where $\hat{u}(k|k)$ and $\hat{d}(k|k)$ can be written as:

% \begin{equation}
% \begin{aligned}
% 	\hat{u}(k) &= \Delta \hat{u}(k|k)+\hat{u}(k-1) \\
% 	\hat{d}(k) &= \Delta \hat{d}(k|k)+\hat{d}(k-1)
% 	\end{aligned}
% \end{equation}

%By using the state equation recursively the state can be predicted up to the prediction horizon as shown in equation \ref{eq:iterating_state_equation}: 
In equation \ref{eq:iterating_state_equation} the recursively use of the state equation is seen. 
% \begin{equation}\label{eq:iterating_state_equation}
% \begin{aligned}
% 	\hat{x}(k+1|k) &= A\hat{x}(k|k)+B(\Delta \hat{u}(k|k)+u(k-1)) + B_d(\hat{d}(k|k)+\hat{d}(k-1))\\
% 	\hat{x}(k+2|k) &= A\hat{x}(k+1|k)+B\hat{u}(k+1|k)+ B_d\hat{d}(k+1|k) \\  
% 				   &= A(A\hat{x}(k|k)+B(\Delta \hat{u}(k|k)+u(k-1)) + B_d(\Delta \hat{d}(k|k)+\hat{d}(k-1)) \\ 
% 				   &+B\hat{u}(k+1|k)+ B_d\hat{d}(k+1|k) \\ 
% 				   &= A^2\hat{x}(k|k)+AB(\Delta \hat{u}(k|k)+u(k-1))+AB_d(\Delta \hat{d}(k|k)+\hat{d}(k-1))\\ 
% 				   & + B\underbrace{(\Delta \hat{u}(k+1)+\Delta \hat{u}(k)+\hat{u}(k-1))}_{\hat{u}(k+1|k)}\\
% 				   & + B_d\underbrace{(\Delta \hat{d}(k+1)+\Delta \hat{d}(k)+\hat{d}(k-1))}_{\hat{d}(k+1|k)} \\ 
% 				   &= A^2 x(k|k) + AB\Delta \hat{u}(k|k)+AB \hat{u}(k-1|k)+B\Delta \hat{u}(k+1|k)\\
% 				   &+	AB\Delta \hat{d}(k|k)+AB \hat{d}(k-1|k)+B\Delta \hat{d}(k+1|k)\\
% 				   &\hspace{2mm}\vdots\\
%    \hat{x}(k+H_p|k)&=A^{H_p}x(k|k)\\
%    				   &+A^{Hp-1}B\Delta \hat{u}(k|k)+ \cdots +B\Delta \hat{u}(k+H_p-1|k) \\
%    				   &+A^{Hp-1}B\hat{u}(k-1|k) \\
%    				   &+A^{Hp-1}B_d\Delta \hat{d}(k|k)+\cdots+B_d\Delta \hat{d}(k+H_p-1|k)\\
%    				   &+A^{Hp-1}B_d\hat{d}(k-1|k)
% \end{aligned}
% \end{equation}

% \begin{equation}\label{eq:iterating_state_equation}
% \begin{aligned}
% 	\hat{x}(k+1|k) &= A\hat{x}(k|k)+B(\Delta \hat{u}(k|k)+u(k-1)) + B_dd(k|k)\\
% 	\hat{x}(k+2|k) &= A\hat{x}(k+1|k)+B\hat{u}(k+1|k)+ B_dd(k+1|k) \\
% 				   &= A^2\hat{x}(k|k)+AB(\Delta \hat{u}(k|k)+u(k-1))+AB_dd(k|k)\\ & + B\underbrace{(\Delta \hat{u}(k+1)+\Delta \hat{u}(k)+u(k-1))}_{\hat{u}(k+1|k)}+ B_dd(k+1|k) \\
% 				   &\hspace{2mm}\vdots\\
%    \hat{x}(k+H_p|k)&= A^{H_p}\hat{x}(k|k)+(A^{H_p-1}+ \cdots +A +I)B\Delta\hat{u}(k|k)+\cdots\\
%    				   &+ (A^{H_p-1}+ \cdots +A +I)B\Delta \hat{u}(k+H_p-1|k) \\	
%    				   &+(A^{H_p-1}+ \cdots +A +I)Bu(k-1)\\
%    				   &+A^{H_p-1}B_dd(k|k)  +\cdots+B_dd(k+H_p-1|k) 
% \end{aligned}
% \end{equation}\fxnote{skal lige gennemskue det her i morgen}

\begin{equation}\label{eq:iterating_state_equation}
\begin{aligned}
	\hat{x}(k+1|k) &= A\hat{x}(k|k)+B\hat{u}(k|k) + B_d\hat{d}(k|k)\\
	\hat{x}(k+2|k) &= A\hat{x}(k+1|k)+B\hat{u}(k+1|k)+ B_d\hat{d}(k+1|k) \\
				   &= A^2\hat{x}(k|k)+AB\hat{u}(k|k)+AB_d\hat{d}(k|k) + B\hat{u}(k+1|k) \\
				   &+ B_d\hat{d}(k+1|k) \\
				   &\hspace{2mm}\vdots\\
   \hat{x}(k+H_p|k)&= A\hat{x}(k+H_p-1|k)+B\hat{u}(k+H_p-1|k)+B_d\hat{d}(k+H_p-1|k)\\
   				   &= A^{H_p}\hat{x}(k|k)+A^{H_p-1}B\hat{u}(k|k)+\cdots+ B\hat{u}(k+H_p-1|k)\\
   				   &+A^{H_p-1}B_d\hat{d}(k|k)+\cdots+B_d\hat{d}(k+H_p-1|k)
\end{aligned}
\end{equation}
Here the first equation $\hat{x}(k+1|k)$ is inserted into the second and this is iterated up to the prediction horizon. This can be set up as prediction vectors and matrices denoted by $\CMcal{X,A,B,U,B}_d$ and $\CMcal{D}$ as shown in equation \ref{eq:lifted_state_equation}.




% \begin{equation}\label{eq:lifted_state_equation}
% \begin{aligned}
% 	  \underbrace{\begin{bmatrix}
% 	  \hat{x}(k+1|k) 	\\
% 	  \hat{x}(k+2|k) 	\\
% 	  \vdots 			\\
% 	  \hat{x}(k+H_p|k) 	\\
% 	   \end{bmatrix}}_{\CMcal{X}}
% 	 &=
% 	\underbrace{\begin{bmatrix}
% 		A \\
% 		A^2 \\
% 		\vdots \\
% 		A^{H_p} \\
% 	\end{bmatrix}}_{\CMcal{A}}
% 	\hat{x}(k|k) 
% 	+	\underbrace{\begin{bmatrix}
% 		B \\
% 		AB \\
% 		\vdots \\
% 		A^{H_p-1}B \\
% 	\end{bmatrix}}_{\CMcal{B}}
% 	\hat{u}(k-1|k)
% 		\\ &+	\underbrace{\begin{bmatrix}
% 		B_d \\
% 		AB_d \\
% 		\vdots \\
% 		A^{H_p-1}B_d \\
% 	\end{bmatrix}}_{\CMcal{B}_d}
% 	\hat{d}(k-1|k) \\
% 	&+
% 	\underbrace{\begin{bmatrix}
% 		B 		 &0			 &\cdots	& 0		\\
% 		AB  	 &B  		 & \cdots& 0		\\
% 		\vdots 	 &\vdots	 & \ddots&\vdots	\\
% 		A^{H_p-1}B&A^{H_p-2}B&\cdots &B 
%     \end{bmatrix}}_{\CMcal{B}_{\Delta \CMcal{U}}}
%     	\underbrace{\begin{bmatrix}
% 	\Delta\hat{u}(k|k)\\
% 	\Delta\hat{u}(k+1|k)\\
% 	\vdots\\
% 	\Delta\hat{u}(k+H_p-1|k)
% 	\end{bmatrix}}_{\Delta\CMcal{U}} \\ &+ 
%     \underbrace{\begin{bmatrix}
%     	B_d 	    &0	         &\cdots & 0		\\
% 		AB_d  	    &B_d  	     & \cdots& 0		\\
% 		\vdots 	    &\vdots	     & \ddots&\vdots	\\
% 		A^{H_p-1}B_d&A^{H_p-2}B_d&\cdots &B_d 
% 	  \end{bmatrix}}_{\CMcal{B}_{\Delta\CMcal{D}}} 
% 	\underbrace{\begin{bmatrix}
% 	\Delta\hat{d}(k|k)\\
% 	\Delta\hat{d}(k+1|k)\\
% 	\vdots\\
% 	\Delta\hat{d}(k+H_p-1|k)
% 	\end{bmatrix}}_{\Delta\CMcal{D}}
% 	\end{aligned}
% \end{equation}

\begin{equation}\label{eq:lifted_state_equation}
\begin{aligned}
	  \underbrace{\begin{bmatrix}
	  \hat{x}(k+1|k) 	\\
	  \hat{x}(k+2|k) 	\\
	  \vdots 			\\
	  \hat{x}(k+H_p|k) 	\\
	   \end{bmatrix}}_{\CMcal{X}}
	 &=
	\underbrace{\begin{bmatrix}
		A \\
		A^2 \\
		\vdots \\
		A^{H_p} \\
	\end{bmatrix}}_{\CMcal{A}}
	\hat{x}(k|k) \\&+
	\underbrace{\begin{bmatrix}
		B 		 &0			 &\cdots	& 0		\\
		AB  	 &B  		 & \cdots& 0		\\
		\vdots 	 &\vdots	 & \ddots&\vdots	\\
		A^{H_p-1}B&A^{H_p-2}B&\cdots &B 
    \end{bmatrix}}_{\CMcal{B}}
    	\underbrace{\begin{bmatrix}
	\hat{u}(k|k)\\
	\hat{u}(k+1|k)\\
	\vdots\\
	\hat{u}(k+H_p-1|k)
	\end{bmatrix}}_{\CMcal{U}} \\ &+ 
    \underbrace{\begin{bmatrix}
    	B_d 	    &0	         &\cdots & 0		\\
		AB_d  	    &B_d  	     & \cdots& 0		\\
		\vdots 	    &\vdots	     & \ddots&\vdots	\\
		A^{H_p-1}B_d&A^{H_p-2}B_d&\cdots &B_d 
 %   	B & \cdots & 0 \\
 %    	AB+B & \cdots & 0 \\
 %    	\vdots & \ddots & \vdots \\
 %    	\sum_{i=0}^{H_u-1}A^i B & \cdots & B \\
 %    	\sum_{i=0}^{H_u}A^i B & \cdots & AB+B\\
 %    	\vdots & \vdots & \vdots \\
 %    	\sum_{i=0}^{H_p-1}A^i B & \cdots & \sum_{i=0}^{H_p-H_u}A^i B \\
	  \end{bmatrix}}_{\CMcal{B}_d} 
	\underbrace{\begin{bmatrix}
	\hat{d}(k|k)\\
	\hat{d}(k+1|k)\\
	\vdots\\
	\hat{d}(k+H_p-1|k)
	\end{bmatrix}}_{\CMcal{D}}
	\end{aligned}
\end{equation}

Where $\CMcal{X}$ is the predicted state vector for the entire prediction horizon. $\CMcal{A}$ is the state matrix up to the prediction horizon. The initial state is $x(k|k)$ and is used to predict over the prediction horizon, $\CMcal{B}$ is the predicted input matrix over the prediction horizon, $\CMcal{U}$ is the predicted input vector, which consists of all the predicted inputs from the current time step until $(k+H_p-1)$. $\CMcal{B}_d$ is the disturbance matrix for the prediction horizon and $\CMcal{D}$ is the disturbance vector. 

This iteration process is also performed for the output equation.

\begin{equation}\label{eq:lifted_output_equation}
	\hat{\CMcal{Y}}(k)= 
	\underbrace{\begin{bmatrix}
	\hat{y}(k+1|k)\\
	\hat{y}(k+2|k)\\
	\vdots\\
	\hat{y}(k+H_p-1|k)
	\end{bmatrix}}_{\CMcal{Y}}
	= 
	\underbrace{\begin{bmatrix}
	C 		& 0 	&\cdots	& 0\\
	0 		& C 	&\cdots & 0 \\
	\vdots	& \vdots&\ddots & 0\\
	0 		& 0		&0 		& C
	\end{bmatrix}}_{\CMcal{C}}
	  \underbrace{\begin{bmatrix}
	  \hat{x}(k+1|k) 	\\
	  \hat{x}(k+2|k) 	\\
	  \vdots 			\\
	  \hat{x}(k+H_p|k) 	\\
	   \end{bmatrix}}_{\CMcal{X}}
\end{equation}
Where $\CMcal{C}$ is a diagonal matrix with the output matrix C in the diagonal. By inserting the predicted state equation \ref{eq:lifted_state_equation}, into the predicted output equation \ref{eq:lifted_output_equation} the following is achieved:

\begin{equation}\label{eq:output_eq_with_state_eq}
	\hat{\CMcal{Y}}(k) =  \CMcal{C}\CMcal{A}\hat{x}(k) +  \CMcal{C}\CMcal{B}\hat{\CMcal{U}}(k) +\CMcal{C}\CMcal{B}_d\hat{\CMcal{D}}(k)
\end{equation}   
% \begin{equation}\label{eq:output_eq_with_state_eq}
% 	\CMcal{Y}(k) =  \CMcal{C}\CMcal{A}x(k) +  \CMcal{C}\CMcal{B}u(k-1)+ \CMcal{C}\CMcal{B}_f\Delta \CMcal{U} +\CMcal{C}\CMcal{B}_d\CMcal{D}(k)
% \end{equation}  

By using the following notation on equation \ref{eq:output_eq_with_state_eq}:


\begin{equation}
 \psi = \CMcal{C}\CMcal{A}  \hspace{5mm} \gamma = \CMcal{C}\CMcal{B} \hspace{5mm}  \Theta = \CMcal{C}\CMcal{B}_{d}
\end{equation}

The predicted output equation can be rewritten as: 

\begin{equation}\label{eq:lifted_output_with_states_inserted}
	\hat{\CMcal{Y}}(k) = \psi \hat{x}(k) + \gamma \hat{\CMcal{U}}(k) + \Theta \hat{\CMcal{D}}(k)
\end{equation}


% \begin{equation}\label{eq:lifted_output_with_states_inserted}
% 	\CMcal{Y}(k) = \psi x(k) + \gamma u(k-1) +\Omega\Delta\CMcal{U}+ \Theta \CMcal{D}(k)
% \end{equation}

To be able to utilize the cost function, in equation \ref{eq:cost_function_height}, it has to be rewritten in terms of the predicted output equation \ref{eq:lifted_output_with_states_inserted}. Thereby replacing the output y with the predicted output $\CMcal{Y}$, the following is obtained:

\begin{equation}\label{eq:new_the_cost_function_yeah}
	\CMcal{J} = ||\hat{\CMcal{Y}}(k)-\hat{\CMcal{Y}}(k-1)||_{\CMcal{Q}(i)}^2
\end{equation}

Where the difference between $\hat{\CMcal{Y}}(k)$ and $\hat{\CMcal{Y}}(k-1)$ can be expressed as:

\begin{equation}\label{eq:differnce_between_y}
	\Delta \hat{\CMcal{Y}}(k) =\hat{\CMcal{Y}}(k)-\hat{\CMcal{Y}}(k-1) 
\end{equation}

Furthermore, it is desired to have the control input as $\Delta \CMcal{U}$ as this will introduce integral action and thereby eliminate steady state error \cite{maciejowski2002predictive}. Doing so, equation \ref{eq:lifted_output_with_states_inserted} is inserted into equation \ref{eq:differnce_between_y} and thereby obtaining:

\begin{equation}\label{eq:delta_output_eq} \begin{aligned}
	\Delta \hat{\CMcal{Y}}(k) &= (\psi \hat{x}(k) + \gamma \hat{\CMcal{U}}(k) + \Theta \hat{\CMcal{D}}(k))-(\psi \hat{x}(k-1) + \gamma \hat{\CMcal{U}}(k-1) + \Theta \hat{\CMcal{D}}(k-1)) \\[8pt]
							  &= \psi\Delta \hat{x}(k) + \gamma\Delta \hat{\CMcal{U}}(k) + \Theta\Delta \hat{\CMcal{D}}(k)
	\end{aligned}
\end{equation}


Thereby $\Delta \CMcal{U}$ is introduced in the predicted output. The cost function in equation \ref{eq:new_the_cost_function_yeah} can be reformulated to the following by using equation \ref{eq:differnce_between_y}:

\begin{equation}\begin{aligned}\label{eq:delta_cost_function}
	\CMcal{J} &= ||\Delta\hat{\CMcal{Y}}(k)||_{\CMcal{Q}(i)}^2\\[6pt]
	  &= \Delta\hat{\CMcal{Y}}(k)^T \cdot Q \cdot \Delta\hat{\CMcal{Y}}(k)
	\end{aligned}
\end{equation}

To be able to write the cost function as quadratic and linear terms of the predicted input, $\Delta\CMcal{U}$, equation \ref{eq:delta_output_eq} is therefore inserted into the cost function, in equation \ref{eq:delta_cost_function}, from which the following is obtained:

\begin{equation}\label{eq:cost_function_with_all_the_crap}
	\CMcal{J} = (\psi\Delta \hat{x}(k) + \gamma\Delta \hat{\CMcal{U}}(k) + \Theta\Delta \hat{\CMcal{D}}(k))^T\cdot Q \cdot (\psi\Delta \hat{x}(k) + \gamma\Delta \hat{\CMcal{U}}(k) + \Theta\Delta \hat{\CMcal{D}}(k))
\end{equation}

% \begin{equation}\label{eq:cost_function_with_all_the_crap}
% \begin{aligned}
% 	\CMcal{J} 	&= (\psi \hat{x}(k) + \gamma u(k-1)+ \Omega \Delta \CMcal{U} + \Theta\CMcal{D}(k))^T\cdot Q \cdot (\psi \hat{x}(k) \\
% 				&+ \gamma u(k-1)+\Omega \Delta \CMcal{U} + \Theta\CMcal{D}(k))
% \end{aligned}
% \end{equation}


The term on the right hand side of equation \ref{eq:cost_function_with_all_the_crap} is equal to:
\begin{equation}\label{eq:cost_function_big_eq}
	\begin{aligned}
	&(\psi\Delta \hat{x}(k) + \gamma\Delta \hat{\CMcal{U}}(k) + \Theta\Delta \hat{\CMcal{D}}(k))^T\cdot Q \cdot (\psi\Delta \hat{x}(k) + \gamma\Delta \hat{\CMcal{U}}(k) + \Theta\Delta \hat{\CMcal{D}}(k)) = \\[10pt]
	& \Delta \hat{x}(k)^T\psi ^T Q \psi \Delta \hat{x}(k) + \underbrace{\Delta \hat{x}(k)^T \psi ^T Q \gamma \Delta  \hat{\CMcal{U}}(k) }_{Linear} +\Delta \hat{x}(k)^T \psi ^T Q \Theta \Delta \hat{\CMcal{D}}(k) \\[8pt]
	& \underbrace{\Delta \hat{\CMcal{U}}(k)^T \gamma ^T Q \psi\Delta \hat{x}(k)}_{Linear} + \underbrace{\Delta \hat{\CMcal{U}}(k)^T\gamma ^T Q \gamma\Delta \hat{\CMcal{U}}(k)}_{Quadratic} +\underbrace{\Delta \hat{\CMcal{U}}(k)^T \gamma ^T Q\Theta \Delta\hat{\CMcal{D}}(k)}_{Linear} \\[8pt] 
	& \Delta \hat{\CMcal{D}}(k)^T \Theta ^T Q  \psi \Delta \hat{x}(k)					+ \underbrace{\Delta \hat{\CMcal{D}}(k)^T \Theta ^T Q \gamma  \Delta \hat{\CMcal{U}}(k) }_{Linear}	+\Delta \hat{\CMcal{D}}(k)^T \Theta ^T Q \Theta \Delta \hat{\CMcal{D}}(k)
		\end{aligned}
\end{equation}
% \begin{equation}\label{eq:cost_function_big_eq}
% 	\begin{aligned}
% 	&(\psi \hat{x}(k) + \gamma u(k-1)+\Omega\Delta\CMcal{U}(k) + \Theta\Delta \CMcal{D}(k))^T\cdot Q \cdot (\psi \hat{x}(k) + \gamma u(k-1)+\Omega\Delta\CMcal{U}(k) \\
% 	& + \Theta\Delta \CMcal{D}(k)) = \\
% 	&  \hat{x}(k)^T\psi ^T Q \psi  \hat{x}(k) +  \hat{x}(k)^T \psi ^T Q \gamma u(k-1)+ \underbrace{\hat{x}(k)^T \psi ^T Q \Omega\Delta\CMcal{U}(k)}_{Linear}\\
% 	& + \hat{x}(k)^T \psi ^T Q \Theta  \CMcal{D}(k) \\
% 	&+ u(k-1)^T \gamma ^T Q \psi \hat{x}(k) +  u(k-1)^T\gamma ^T Q \gamma u(k-1) +\underbrace{ u(k-1)^T \gamma Q \Omega\Delta\CMcal{U}(k)k)}_{Linear}\\
% 	&+ u(k-1)^T \gamma ^T Q\Theta \CMcal{D}(k) \\ 
% 	&+ \underbrace{\Delta\CMcal{U}(k)^T\gamma^TQ \psi  \hat{x}(k)}_{Linear} +  \underbrace{\Delta\CMcal{U}(k)^T\gamma^TQ \gamma u(k-1)}_{Linear}+ \underbrace{\Delta\CMcal{U}(k)^T\gamma^TQ \Omega\Delta\CMcal{U}(k)}_{Quadradic} \\
% 	&+ \underbrace{\Delta\CMcal{U}(k)^T\gamma^T Q \Theta  \CMcal{D}(k)}_{Linear} \\
% 	&+\CMcal{D}(k)^T \Theta ^T Q  \psi  \hat{x}(k)	+  \CMcal{D}(k)^T \Theta ^T Q \gamma u(k-1)+ \underbrace{\CMcal{D}(k)^T \Theta ^T Q   \Omega\Delta\CMcal{U}(k)}_{Linear}\\
% 	&+ \CMcal{D}(k)^T \Theta ^T Q \Theta \CMcal{D}(k)
% 	\end{aligned}
% \end{equation}

The quadratic and linear terms of $\Delta \CMcal{U}$ are denoted respectively, the remaining terms which are not denoted in the equation are constants, that will be referred to in the following equations as the constant c. The quadratic variables are collected in: 

\begin{equation}\label{eq:quadratic_h_matrix}
	\CMcal{H} = \gamma^T Q\gamma 
\end{equation}

And the linear variables are collected in:
\begin{equation}
	\begin{aligned}
	\CMcal{G} &= 2 \Delta \hat{x}(k)^T\psi^T Q \gamma+2 \Delta \hat{\CMcal{D}}(k)^T\Theta^T Q \gamma 
	%\CMcal{G} &= 2 \cdot \hat{x}(k)^T\psi^T Q \Omega+2\cdot u(k-1)^T\gamma^T Q\Omega+2\cdot  \CMcal{D}(k)^T\Theta^T Q \Omega
	\end{aligned}
\end{equation}

Thereby inserting these expressions in equation \ref{eq:cost_function_big_eq} the following cost function is obtained:

\begin{equation}\label{eq:the_cost_function}
	\min_{\Delta \CMcal{U}(k)} \CMcal{J}(\Delta \CMcal{U}(k)) =\min_{\Delta \CMcal{U}(k)} \Delta \CMcal{U}(k)^T\CMcal{H}\Delta \CMcal{U}(k)+\CMcal{G}\Delta \CMcal{U}(k)+c
\end{equation}

In the following the constraints, which the cost function is subject to, will be elaborated. 

\subsection{Constraints}\label{subse:constraints}

In order to apply the constraints, shown in equation \ref{eq:cost_function_height} on the states, to the optimization problem in equation \ref{eq:the_cost_function} the constraints must be reformulated so they are a constraint of the control input $\Delta\CMcal{U}$. Therefore it is required to reformulate the inequality constraints. 

The constraints applied to the states are upper and lower bound to the pipe and the tank. 
This will if possible limit over- and underflow in pipes and tanks due to the nature of the linearized model.
%This will not allow the simulation to overfill the pipe or the tank, or to have a negative height in either of the two. 
In the following equation the constraints for the predicted states are shown:  


\begin{equation}
    x_{min} \leq \CMcal{X}(k) \leq x_{max}
\end{equation}

Where $x_{min}$ and $x_{max}$ are respectively lower and upper bound. Considerations are needed as the linear model is a small signal model and the constraints are made for the nonlinear simulation. The linearization point therefore needs to be subtracted from the lower and upper bounds which thereby transforms the constraints into small signal constraints.

%As the constraint needs to be for the small signal value and as the constraint is for full signal values the operating point needs to be subtracted from the lower and upper bounds thereby transforming the constraint into small signals:

\begin{equation}
    x_{min}- \bar{x} \leq \hat{\CMcal{X}}(k) \leq x_{max}-\bar{x}
\end{equation}

To reformulated the constraints the predicted state equation in equation \ref{eq:lifted_state_equation} is inserted in place of the state vector.

\begin{equation}\label{eq:constraint_states}
	x_{min}- \bar{x} \leq \CMcal{A}\hat{x}(k)+\CMcal{B}\hat{\CMcal{U}}(k)+\CMcal{B\hat{D}}(k) \leq x_{max}-\bar{x}
     %x_{min}- \bar{x} \leq \CMcal{A}\hat{x}(k)+\CMcal{B}u(k-1)+\CMcal{B}_f\Delta\CMcal{U}(k)+\CMcal{BD}(k) \leq x_{max}-\bar{x}
 \end{equation} 

However, to make the constraints depending on $\Delta \CMcal{U}$, the predicted input can be formulated as $\CMcal{U}(k) = \CMcal{V}u(k-1) +W\Delta \CMcal{U}(k) $, where $\CMcal{V}$ is a vector and W is a matrix on the form: 

\begin{equation}
\CMcal{V}=
	\begin{bmatrix}
	  \CMcal{V}_1 	\\
	  \CMcal{V}_2 	\\
	  \vdots 			\\
	  \CMcal{V}_{H_p} 	\\
	  \end{bmatrix}
	  = 
	  \begin{bmatrix}
	  1 	\\
	  1 	\\
	  \vdots 			\\
	  1 	\\
	  \end{bmatrix}
\end{equation}
\begin{equation}
	W=	  
\begin{bmatrix}
	  w_{1,1}  & w_{1,2} & w_{1,3} & w_{1,H_p} 	\\
	  w_{1,2}  & w_{2,2} & w_{2,3} & w_{2,H_p} 	\\
	  w_{1,3}  & \vdots & \ddots & w_{3,H_p}		\\
	  w_{H_p,1} & w_{H_p,2} & \cdots & w_{H_p,H_p} 	\\
	  \end{bmatrix}=
	  \begin{bmatrix}
	  1 & 0 & 0 & 0 	\\
	  1 & 1 & 0 & 0 	\\
	  1 & \vdots & \ddots & 0		\\
	  1 & 1 & \cdots & 1 	\\
	  \end{bmatrix}
\end{equation}

Inserting this into equation \ref{eq:constraint_states} the follwing is obtained:

\begin{equation}
	x_{min}- \bar{x} \leq \CMcal{A}\hat{x}(k)+\CMcal{B}\CMcal{V}\hat{u}(k-1) +\CMcal{B}W\Delta \hat{\CMcal{U}}(k)+\CMcal{B\hat{D}}(k) \leq x_{max}-\bar{x}
     %x_{min}- \bar{x} \leq \CMcal{A}\hat{x}(k)+\CMcal{B}u(k-1)+\CMcal{B}_f\Delta\CMcal{U}(k)+\CMcal{BD}(k) \leq x_{max}-\bar{x}
 \end{equation} 
% This is inserted in the following equation: 

% \begin{equation}
%      x_{min}- \bar{x} \leq \CMcal{A}\hat{x}(k)+\CMcal{B}(\CMcal{U}(k-1)+\sum_{i=1}^n \Delta\CMcal{U}(k+i-1))+\CMcal{B}\CMcal{D}(k) \leq x_{max}-\bar{x}
%  \end{equation} 


 Having set the constraints up as a constraint on the input signal they furthermore has to be set up as equality constraints. Therefore are they divided into two constraints one for the upper bound and one for the lower bound. 

 \begin{equation}
 \begin{aligned}
 x_{max}-\bar{x} &\geq \CMcal{A}\hat{x}(k)+\CMcal{B}\CMcal{V}\hat{u}(k-1) +\CMcal{B}W\Delta \hat{\CMcal{U}}(k)+\CMcal{B\hat{D}}(k)\\[10pt]
 \underbrace{\CMcal{B}W}_{\Lambda} \Delta\hat{\CMcal{U}}(k)&\leq \underbrace{x_{max}- \bar{x}-\CMcal{A}\hat{x}(k)-\CMcal{B}\CMcal{V}\hat{u}(k-1)-\CMcal{B}\hat{\CMcal{D}}(k)}_{\Gamma_1}
        %\CMcal{B}_f\Delta\CMcal{U}(k)\leq \underbrace{x_{max}- \bar{x}-\CMcal{A}x(k)-\CMcal{B}u(k-1)-\CMcal{B}\CMcal{D}(k)}_{\Gamma_1}
\end{aligned}
 \end{equation}  

 \begin{equation}
 \begin{aligned}
 x_{min}- \bar{x} &\leq \CMcal{A}\hat{x}(k)+\CMcal{B}\CMcal{V}\hat{u}(k-1) +\CMcal{B}W\Delta \hat{\CMcal{U}}(k)+\CMcal{B\hat{D}}(k)\\[10pt]
 \underbrace{\CMcal{B}W}_{\Lambda} \Delta\hat{\CMcal{U}}(k) &\leq \underbrace{-x_{min}+\bar{x}+\CMcal{A}\hat{x}(k)+\CMcal{B}\CMcal{V}\hat{u}(k-1)+\CMcal{B}\hat{\CMcal{D}}(k)}_{\Gamma_2}
   % -\CMcal{B}_f\Delta\CMcal{U}(k) \leq \underbrace{-x_{min}+\bar{x}+\CMcal{A}x(k)+\CMcal{B}u(k-1)+\CMcal{B}\CMcal{D}(k)}_{\Gamma_2}
  \end{aligned}
 \end{equation}


Constraints are also applied to the control output. The reason for these constraints is to not allow the controller to produce an output that will cause overflow in the pipe after the tank. The constraint on the control output is constructed in the same way as for the states. Below the constraint for the control output is shown:  
 \begin{equation}
 	u_{min} \leq \CMcal{U}(k) \leq u_{max}
 \end{equation}

The constraint needs to be written for small signal values, and need to depend on $\Delta \CMcal{U}$:

 \begin{equation}
 		u_{min} -  \bar{u} \leq \CMcal{V}\hat{u}(k-1)+ W\Delta\hat{\CMcal{U}}(k)  \leq  u_{max} -  \bar{u}
 \end{equation}

The constraint is split up into lower and upper bound for the signal, the upper bound is:

 \begin{equation}
 \begin{aligned}
			 	\CMcal{V}\hat{u}(k-1)+W \Delta\hat{\CMcal{U}}(k)  &\leq  u_{max} -  \bar{u} \\
				W\Delta\hat{\CMcal{U}}(k)  &\leq  \underbrace{u_{max} -  \bar{u} - \CMcal{V}\hat{u}(k-1)}_{\Gamma_3} \\
 \end{aligned}
 \end{equation}



And the lower bound:

 \begin{equation}
 \begin{aligned}
			 	u_{min} -  \bar{u} &\leq \CMcal{V}\hat{u}(k-1)+W \Delta\hat{\CMcal{U}}(k) \\
-W\Delta\hat{\CMcal{U}}(k) &\leq \underbrace{\CMcal{V}\hat{u}(k-1)-u_{min}+\bar{u}}_{\Gamma_4}
 \end{aligned}
 \end{equation}

The constraints can be put on standard inequality constraint form and thereby be included in the algorithm for the MPC implementation.

 \begin{equation}
        \begin{bmatrix}
           \Lambda\\
           -\Lambda\\
           W \\
           -W
           \end{bmatrix}
           \Delta\CMcal{U}
           \leq 
           \begin{bmatrix}
         \Gamma_{1.max}\\
         \Gamma_{2.min}\\
         \Gamma_{3.max}\\
         \Gamma_{4.min}

           \end{bmatrix}
 \end{equation}\label{eq:constriants_eq}

 In the following section, the implementation of the cost function and constraints, shown in this section, in MATLAB will be elaborated

\subsection{Implementation of MPC}\label{subse:implementation_mpc}
In this section the implementation of MPC in MATLAB will be elaborated. 

The cost function in equation \ref{eq:the_cost_function} is a quadratic problem. In order to solve this minimization problem and find a global minimum, quadratic programming (QP) is utilized. In MATLAB there exist several solvers for QP problems, in this project Quadprog is the chosen solver. Quadprog solves the minimization problem subject to constraints to the specified convex cost function. The model used as the predictive model is the linear model obtained in section \ref{se:linearization}. Furthermore, the constraints the cost is subject to, as explained in the previous section, is also included. 

In figure \ref{fig:mpc_diagram} an illustration of a MPC controller is shown.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.70\textwidth]{report/control/pictures/mpc_diagram}
	\caption{Diagram of MPC controller.}
	\label{fig:mpc_diagram}
\end{figure}

Here it is illustrated that the model, constraint and cost function will be used in the optimizer to generate a control output. This will be used in the process, which in this case is the nonlinear model. The output y(k+1) is the output height at the end of the last pipe in the sewer network, which corresponds to the input of the WWTP. At each time step, the current value of the output is returned to the MPC controller. Here the MPC will at each iteration calculate up to $H_p$ control inputs, however, only the first element within the u vector will be used to control the process. Thereafter a new measurement will be taken and a new control output will be calculated. This procedure will iterate for the entire simulation.

In determining the length of the prediction horizon several considerations were taken into account. In figure \ref{fig:input_to_wwtp} a daily flow from the households is shown. The flow is illustrated for working days and weekend. By knowing the wastewater flow pattern from households the MPC would be able to include this knowledge in the prediction model. Thus an ideal prediction horizon would be 24 hours, as it would be able to see the disturbance across a whole day. 

However, as the households are not the only disturbance in this setup this is not entirely true. Because the output from the larger industry e.g. the bottling plant and the brewery are stochastic can be let into the sewer without warning and the periodicity between the outlets are unknown. Furthermore, the amount of wastewater coming from the industry also varies between outlets. Therefore, it would be preferable not to place the tank next to the industry as it would not be able to predict the disturbance. 
Thus the tank should be placed at a distance from the industry, where the distance can be used in the prediction model by measurements obtained at the outlet of the industry.% the disturbance coming from the industry by having a measurement of it. 

During implementation of the MPC controller, it was discovered that the prediction horizon was restricted. It was not possible to set it higher than 20 iterations or 400 seconds, as the quadratic matrix $\CMcal{H}$ then became non-convex. The reason is most likely to be found in the linearized model, as some of the elements in the matrices are small, which can result in numerical problems. Therefore, when the system is predicted, it would cause the $\CMcal{H}$ matrix to have negative eigenvalues. Several tests were conducted to find a prediction horizon that did not result in a negative eigenvalue. A prediction horizon of 400 seconds equal to 20 iterations, would give a quadratic matrix which was convex. However, this restricts the distance from the tank, as the MPC were not able to predict far enough into the future to see the point where the flow variations are to be minimized. Therefore, in the simulation of the MPC controller, this must be kept in mind.   

\subsection*{Results}
In this subsection, the results obtained from testing the MPC controller will be covered. Two simulations will be conducted, one where the constraints are neglected and therefore the problem is minimized without any restriction and another simulation where the constraints are included. 

The pipe and tank setup for the simulation includes two pipes and one tank, where the tank is placed in between of the pipes. The specification for both pipes and the tank can be seen in tabular \ref{tab:pipe_data_for_mpc_test} and \ref{tab:tank_data_for_mpc_test} respectively.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
	\rowcolor[HTML]{9B9B9B} 
\textbf{Pipe number} & \textbf{Length} [m] & \textbf{Sections} & \textbf{Dx} [m] & \textbf{$S_b$} & \textbf{d} [m] & \textbf{$\theta$} & \textbf{Qf $[m^3/s]$} \\ \hline
1&100             & 5                 & 20          & 0,003       & 0,9        & 0,65              & 0,97        \\ \hline
2&100             & 5                 & 20          & 0,003       & 0,9        & 0,65              & 0,97        \\ \hline
\end{tabular}
\caption{The pipe specification for the simulation.}
\label{tab:pipe_data_for_mpc_test}
\end{table}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Size $[m^3]$}        & 90   \\ \hline
\textbf{Height $[m]$}      & 10   \\ \hline
\textbf{Area $[m^2]$}        & 9    \\ \hline
\textbf{Q\_out\_max} $[m^3/s]$& 0,97 \\ \hline
\end{tabular}
\caption{Tank specification for the simulation.}
\label{tab:tank_data_for_mpc_test}
\end{table}

In the first simulation the MPC controller is minimizing the output variations of the tank without any constraints. The input signal into the first pipe is shown in figure \ref{fig:input_to_pipe_mpc_test}. 
\begin{figure}[H]
 \centering
 \input{report/control/tikz/MPC_test_control_input}
\caption{Input to the first pipe.}
\label{fig:input_to_pipe_mpc_test}
\end{figure}

A constant input of 0,2 $m^3/s$, which results in a height of 0,31 meters in the pipe is given. On top of the input, a disturbance signal is added. This is done to verify the functionality of the MPC, being able to keep the flow variations out of the tank at a minimum. The disturbance signal is a triangular signal which spans from zero up to 0,7 $m^3/s$, which is equal to a height of 0,75 meters in the pipe when taking the constant input into consideration. The time between each disturbance peak is 200 seconds and the period of the disturbance is 100 seconds. The simulation conducted for two hours where $\Delta t$ is set to 20 seconds. In figure \ref{fig:MPC_test_output_first_test} the output of the last pipe is shown.  


\begin{figure}[H]
 \centering
 \input{report/control/tikz/MPC_test_output_first_test}
\caption{Output of the last pipe.}
\label{fig:MPC_test_output_first_test}
\end{figure}

Here it can be seen that the MPC controller is able to minimize the disturbance coming from the first pipe as the output is constant. At the beginning the height of the output is a bit higher, this is due to that the tank holds wastewater at the beginning of the simulation. After it is emptied the height falls to a constant level. In figure \ref{fig:tank_height_first_test} the fluid height within the tank can be seen.  

\begin{figure}[H]
 \centering
 \input{report/control/tikz/tank_height_first_test}
\caption{Height in the tank.}
\label{fig:tank_height_first_test}
\end{figure}

As expected the tank would be overfilled, as the disturbance coming from the first pipe is much higher than the output of the second. However, the cost function does what is expected, as it keeps a steady output of the tank and has no knowledge about the limitations of the tank and therefore causes overflow. In the second simulation the same input is applied to the first pipe, where the constraints shown in equation \ref{eq:constriants_eq} is utilized. In this simulation, only constraints regarding the tank and the control input to the pump is applied. The reason for not having constraints on the height in the second pipe is, that it should be sufficient to have constraints on the control input to the pump. As only inputs between zero and one is allowed. 
%where the constant is multiplied on the maximum flow that the second pipe can transfer and thereby not allow flows higher than that. 
Furthermore, the height constraints for the tank goes from 0 to the maximum height which is set to 10 meters, in this simulation, as seen in table \ref{tab:tank_data_for_mpc_test}. The reason for not having constraints on the first pipe is, that it is impossible for the MPC controller to regulate the height in that part. In figure \ref{fig:tank_height_second_test_with_constraints} the height of the tank is shown from the second simulation.        


\begin{figure}[H]
 \centering
 \input{report/control/tikz/tank_height_second_test_with_constraints}
\caption{Height in the tank at the second simulation run.}
\label{fig:tank_height_second_test_with_constraints}
\end{figure}

It can be seen that the tank does not overflow, thereby it is within the constraints of the tank. At the start of the simulation, the tank is emptied once again. Hereafter the tank is continuously filled with fluid to a level of two meters and then emptied again. In figure \ref{fig:MPC_test_output_second_test_with_constraints} the output of the second pipe is shown. 

\begin{figure}[H]
 \centering
 \input{report/control/tikz/MPC_test_output_second_test_with_constraints}
\caption{Output of the last pipe in the second simulation run.}
\label{fig:MPC_test_output_second_test_with_constraints}
\end{figure}

It is clear from the figure that the variations in the output are not minimized. It fluctuates between two values, the constant input of approximately 0,31 meters and 0,51 meters. In the top and bottom of the curve, it can be seen that the curve flattens. The bottom is due to the tank is empty and therefore, the input, that goes into the tank from the first pipe, goes right into the second pipe without any storage occurring in the tank. When the top flattens the tank start to be filled up, and as it goes down the tank is emptied. It was discovered that the reason for the top is due to constraints on the upper bound for the input, this however, is not a wanted feature. It was desired to get a constant output or a minimum of variations in the output, which is not achieved. Through several tries of changing the parameters of the constraints, e.g. lessen the controller constraints and trying to changing the height of the tank. However, a solution was not found.

The MPC controller does not function as intended and will be concluded upon in the discussion, however in the following chapter the results of the simulation model over the northern part of Fredericia is shown.







